{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8/JP63D/BRI7AXw03DBRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Usman-938/Assignments/blob/main/7_Tasks_week_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQBgQlrB1t_T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8759ac82"
      },
      "source": [
        "# Task\n",
        "Read the content of the `/content/Tasks (1).docx` file and summarize the tasks and headings within it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ac13dc4"
      },
      "source": [
        "## Read Document Content\n",
        "\n",
        "### Subtask:\n",
        "Read the content of the `/content/Tasks (1).docx` file to access the tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2443dc8"
      },
      "source": [
        "**Reasoning**:\n",
        "To read a .docx file, I need to use the `python-docx` library. The first step is to import the `Document` class from the `docx` module and then use it to open the specified document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "6a61cd0e",
        "outputId": "7a02e224-38d2-4b3d-e9ef-9f455c197be7"
      },
      "source": [
        "from docx import Document\n",
        "\n",
        "# Open the document\n",
        "document = Document('/content/Tasks (1).docx')\n",
        "\n",
        "print(\"Document loaded successfully.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'docx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-678190144.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Open the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Tasks (1).docx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'docx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de09d5c8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the `python-docx` library was not installed. I need to install it first using `!pip install python-docx`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "41b9e6ef",
        "outputId": "3c202aa9-9b41-45be-d56c-25e465666239"
      },
      "source": [
        "pip install python-docx\n",
        "print(\"python-docx library installed successfully.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-565892798.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-565892798.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install python-docx\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c996f8d"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `pip install` command resulted in a `SyntaxError` because it was not prefixed with `!`. I need to add `!` to execute it as a shell command in the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3813e4d",
        "outputId": "7719c2ad-175b-47d7-e31c-7011a9b2853c"
      },
      "source": [
        "!pip install python-docx\n",
        "print(\"python-docx library installed successfully.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/253.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n",
            "python-docx library installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc8e4cb4"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the `python-docx` library has been successfully installed, I will now attempt to open the document again using the `Document` class, as was the original intention.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52c597c5",
        "outputId": "f9e67a77-7c74-4ecd-d2c6-734d19615eba"
      },
      "source": [
        "from docx import Document\n",
        "\n",
        "# Open the document\n",
        "document = Document('/content/Tasks (1).docx')\n",
        "\n",
        "print(\"Document loaded successfully.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e5872a8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the document is loaded, I need to extract its content, specifically the text from all paragraphs and headings, to fulfill the subtask requirement of reading the content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d47a1f4",
        "outputId": "8fb993fd-366c-4b62-f46e-badb850ee8e4"
      },
      "source": [
        "full_text = []\n",
        "for paragraph in document.paragraphs:\n",
        "    full_text.append(paragraph.text)\n",
        "\n",
        "# Also extract headings if any\n",
        "headings = []\n",
        "for paragraph in document.paragraphs:\n",
        "    if paragraph.style.name.startswith('Heading'):\n",
        "        headings.append(paragraph.text)\n",
        "\n",
        "print(\"Extracted document text and headings.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted document text and headings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bb87366"
      },
      "source": [
        "## Extract Headings and Tasks\n",
        "\n",
        "### Subtask:\n",
        "Parse the document to identify all headings and the tasks described under each heading.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b024f31"
      },
      "source": [
        "**Reasoning**:\n",
        "To parse the document content, identify headings, and associate tasks with them, I will implement the provided logic to iterate through paragraphs and categorize text based on predefined heading keywords.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c1023ea",
        "outputId": "3012f1d8-77cb-412d-aaa9-82fe7ecbd9f3"
      },
      "source": [
        "extracted_content = []\n",
        "current_heading = None\n",
        "current_tasks = []\n",
        "\n",
        "heading_keywords = ['TASK', 'Real-World Problem:', 'Your Objective:', 'Tasks', 'Hint Code', 'What You Learn']\n",
        "\n",
        "for paragraph in document.paragraphs:\n",
        "    paragraph_text = paragraph.text.strip()\n",
        "\n",
        "    is_heading = False\n",
        "    for keyword in heading_keywords:\n",
        "        if paragraph_text.startswith(keyword) and len(paragraph_text) > len(keyword) and (paragraph_text[len(keyword)] == ' ' or paragraph_text[len(keyword)] == '—' or paragraph_text[len(keyword)] == ':'):\n",
        "            is_heading = True\n",
        "            break\n",
        "        elif paragraph_text == keyword: # For exact matches like 'Tasks' or 'What You Learn'\n",
        "            is_heading = True\n",
        "            break\n",
        "\n",
        "    if is_heading:\n",
        "        if current_heading is not None:\n",
        "            extracted_content.append({\n",
        "                'heading': current_heading,\n",
        "                'content': current_tasks\n",
        "            })\n",
        "        current_heading = paragraph_text\n",
        "        current_tasks = []\n",
        "    elif paragraph_text:\n",
        "        current_tasks.append(paragraph_text)\n",
        "\n",
        "# Append the last heading and its content\n",
        "if current_heading is not None:\n",
        "    extracted_content.append({\n",
        "        'heading': current_heading,\n",
        "        'content': current_tasks\n",
        "    })\n",
        "\n",
        "print(\"Extracted content structure:\")\n",
        "for item in extracted_content:\n",
        "    print(f\"Heading: {item['heading']}\")\n",
        "    for task in item['content']:\n",
        "        print(f\"  - {task}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted content structure:\n",
            "Heading: TASK 1 — SMART SURVEILLANCE (IMAGE DATA)\n",
            "Heading: Real-World Problem: A shopping mall wants to detect crowd density using CCTV cameras.\n",
            "Heading: Your Objective: Prepare image data correctly for an ML model.\n",
            "Heading: Tasks\n",
            "  - Simulate an RGB image (224, 224, 3)\n",
            "  - Create a batch of 16 images\n",
            "  - Print shapes and explain each dimension\n",
            "Heading: Hint Code\n",
            "  - import numpy as np\n",
            "  - images = np.random.rand(16, 224, 224, 3)\n",
            "  - print(images.shape)\n",
            "Heading: What You Learn\n",
            "  - Tensor shapes\n",
            "  - Batch processing\n",
            "  - Image ML pipeline\n",
            "Heading: TASK 2 — VIDEO ACTIVITY RECOGNITION\n",
            "Heading: Real-World Problem: A security system wants to detect running vs walking from videos.\n",
            "Heading: Your Objective: Understand how video data is stored for ML.\n",
            "Heading: Tasks\n",
            "  - Simulate a 10-second video (30 FPS → 300 frames)\n",
            "  - Store as a tensor\n",
            "  - Add batch size\n",
            "Heading: Hint Code\n",
            "  - video = np.random.rand(1, 300, 224, 224, 3)\n",
            "  - print(video.shape)\n",
            "Heading: What You Learn\n",
            "  - Time dimension\n",
            "  - Video tensors\n",
            "  - 3D CNN inputs\n",
            "Heading: TASK 3 — CUSTOMER CHURN RISK (PROBABILITY)\n",
            "Heading: Real-World Problem: A telecom company wants to predict customer churn risk.\n",
            "Heading: Your Objective: Calculate probability and interpret confidence.\n",
            "Heading: Tasks\n",
            "  - Simulate churn predictions\n",
            "  - Calculate probability of churn\n",
            "  - Decide a threshold (e.g., 0.7)\n",
            "Heading: Hint Code\n",
            "  - predictions = np.random.rand(20)\n",
            "  - high_risk = predictions[predictions > 0.7]\n",
            "  - print(\"High-risk customers:\", len(high_risk))\n",
            "Heading: What You Learn\n",
            "  - Probability outputs\n",
            "  - Decision thresholds\n",
            "  - Business impact\n",
            "Heading: TASK 4 — FEATURE CORRELATION (SALES DATA)\n",
            "Heading: Real-World Problem: A company wants to know if advertising budget affects sales.\n",
            "Heading: Your Objective: Analyze feature relationships.\n",
            "Heading: Tasks\n",
            "  - Create two numerical lists\n",
            "  - Calculate correlation\n",
            "  - Interpret result\n",
            "Heading: Hint Code\n",
            "  - ads = [100, 200, 300, 400, 500]\n",
            "  - sales = [10, 20, 30, 40, 50]\n",
            "  - import numpy as np\n",
            "  - print(np.corrcoef(ads, sales))\n",
            "Heading: What You Learn\n",
            "  - Feature relevance\n",
            "  - Correlation intuition\n",
            "  - Feature selection\n",
            "Heading: TASK 5 — MODEL LEARNING SIMULATION\n",
            "Heading: Real-World Problem: A startup wants to understand why model training takes time.\n",
            "Heading: Your Objective: Simulate learning using gradient descent.\n",
            "Heading: Tasks\n",
            "  - Initialize a weight\n",
            "  - Reduce loss step by step\n",
            "  - Observe improvement\n",
            "Heading: Hint Code\n",
            "  - w = 20\n",
            "  - lr = 0.1\n",
            "  - for i in range(10):\n",
            "  - loss = w**2\n",
            "  - w = w - lr * (2*w)\n",
            "  - print(f\"Step {i}, Weight {w:.2f}, Loss {loss:.2f}\")\n",
            "Heading: What You Learn\n",
            "  - Loss\n",
            "  - Gradient\n",
            "  - Learning process\n",
            "Heading: TASK 6 — IMAGE vs VIDEO MEMORY COST\n",
            "Heading: Real-World Problem: A company needs to estimate GPU memory usage.\n",
            "Heading: Your Objective: Compare memory usage of image and video tensors.\n",
            "Heading: Tasks\n",
            "  - Create image tensor\n",
            "  - Create video tensor\n",
            "  - Compare .nbytes\n",
            "Heading: Hint Code\n",
            "  - img = np.random.rand(224,224,3)\n",
            "  - vid = np.random.rand(30,224,224,3)\n",
            "  - print(\"Image bytes:\", img.nbytes)\n",
            "  - print(\"Video bytes:\", vid.nbytes)\n",
            "Heading: What You Learn\n",
            "  - Why video models are expensive\n",
            "  - Resource planning\n",
            "Heading: TASK 7 — MINI BUSINESS DECISION\n",
            "Heading: Real-World Problem: An AI system flags fraud transactions.\n",
            "Heading: Your Objective: Decide a threshold that balances risk and cost.\n",
            "Heading: Tasks\n",
            "  - Generate random fraud probabilities\n",
            "  - Try thresholds 0.5, 0.7, 0.9\n",
            "  - Compare flagged cases\n",
            "Heading: Hint Code\n",
            "  - scores = np.random.rand(50)\n",
            "  - for t in [0.5, 0.7, 0.9]:\n",
            "  - print(f\"Threshold {t}: {len(scores[scores>t])} alerts\")\n",
            "Heading: What You Learn\n",
            "  - Threshold tuning\n",
            "  - ML + business trade-offs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8aaac3"
      },
      "source": [
        "## List Identified Tasks\n",
        "\n",
        "### Subtask:\n",
        "Present a clear list of all identified headings and their associated tasks, asking for further instructions on how to complete them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a071ad4"
      },
      "source": [
        "## Identified Headings and Tasks\n",
        "\n",
        "```python\n",
        "output_markdown = \"\"\n",
        "for item in extracted_content:\n",
        "    output_markdown += f\"### {item['heading']}\\n\"\n",
        "    if item['content']:\n",
        "        for task in item['content']:\n",
        "            output_markdown += f\"- {task}\\n\"\n",
        "    else:\n",
        "        output_markdown += \"- No specific tasks listed under this heading.\\n\"\n",
        "\n",
        "output_markdown += \"\\n\\n---\\n\\nNow that the headings and tasks have been identified, please let me know which specific task you would like to proceed with, or if you have any other instructions.\\n\"\n",
        "\n",
        "print(output_markdown)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f42507fc"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires presenting the identified headings and tasks. The previous markdown block contained Python code to format this output. Now, I will execute this Python code to generate a clear, formatted list of all identified headings and their associated tasks, and then ask for further instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b15bcdb5",
        "outputId": "cc4e1f52-36d6-4b06-bd07-9a6f70de1d0f"
      },
      "source": [
        "output_markdown = \"\"\n",
        "for item in extracted_content:\n",
        "    output_markdown += f\"### {item['heading']}\\n\"\n",
        "    if item['content']:\n",
        "        for task in item['content']:\n",
        "            output_markdown += f\"- {task}\\n\"\n",
        "    else:\n",
        "        output_markdown += \"- No specific tasks listed under this heading.\\n\"\n",
        "\n",
        "output_markdown += \"\\n\\n---\\n\\nNow that the headings and tasks have been identified, please let me know which specific task you would like to proceed with, or if you have any other instructions.\\n\"\n",
        "\n",
        "print(output_markdown)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### TASK 1 — SMART SURVEILLANCE (IMAGE DATA)\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A shopping mall wants to detect crowd density using CCTV cameras.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Prepare image data correctly for an ML model.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Simulate an RGB image (224, 224, 3)\n",
            "- Create a batch of 16 images\n",
            "- Print shapes and explain each dimension\n",
            "### Hint Code\n",
            "- import numpy as np\n",
            "- images = np.random.rand(16, 224, 224, 3)\n",
            "- print(images.shape)\n",
            "### What You Learn\n",
            "- Tensor shapes\n",
            "- Batch processing\n",
            "- Image ML pipeline\n",
            "### TASK 2 — VIDEO ACTIVITY RECOGNITION\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A security system wants to detect running vs walking from videos.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Understand how video data is stored for ML.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Simulate a 10-second video (30 FPS → 300 frames)\n",
            "- Store as a tensor\n",
            "- Add batch size\n",
            "### Hint Code\n",
            "- video = np.random.rand(1, 300, 224, 224, 3)\n",
            "- print(video.shape)\n",
            "### What You Learn\n",
            "- Time dimension\n",
            "- Video tensors\n",
            "- 3D CNN inputs\n",
            "### TASK 3 — CUSTOMER CHURN RISK (PROBABILITY)\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A telecom company wants to predict customer churn risk.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Calculate probability and interpret confidence.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Simulate churn predictions\n",
            "- Calculate probability of churn\n",
            "- Decide a threshold (e.g., 0.7)\n",
            "### Hint Code\n",
            "- predictions = np.random.rand(20)\n",
            "- high_risk = predictions[predictions > 0.7]\n",
            "- print(\"High-risk customers:\", len(high_risk))\n",
            "### What You Learn\n",
            "- Probability outputs\n",
            "- Decision thresholds\n",
            "- Business impact\n",
            "### TASK 4 — FEATURE CORRELATION (SALES DATA)\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A company wants to know if advertising budget affects sales.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Analyze feature relationships.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Create two numerical lists\n",
            "- Calculate correlation\n",
            "- Interpret result\n",
            "### Hint Code\n",
            "- ads = [100, 200, 300, 400, 500]\n",
            "- sales = [10, 20, 30, 40, 50]\n",
            "- import numpy as np\n",
            "- print(np.corrcoef(ads, sales))\n",
            "### What You Learn\n",
            "- Feature relevance\n",
            "- Correlation intuition\n",
            "- Feature selection\n",
            "### TASK 5 — MODEL LEARNING SIMULATION\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A startup wants to understand why model training takes time.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Simulate learning using gradient descent.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Initialize a weight\n",
            "- Reduce loss step by step\n",
            "- Observe improvement\n",
            "### Hint Code\n",
            "- w = 20\n",
            "- lr = 0.1\n",
            "- for i in range(10):\n",
            "- loss = w**2\n",
            "- w = w - lr * (2*w)\n",
            "- print(f\"Step {i}, Weight {w:.2f}, Loss {loss:.2f}\")\n",
            "### What You Learn\n",
            "- Loss\n",
            "- Gradient\n",
            "- Learning process\n",
            "### TASK 6 — IMAGE vs VIDEO MEMORY COST\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: A company needs to estimate GPU memory usage.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Compare memory usage of image and video tensors.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Create image tensor\n",
            "- Create video tensor\n",
            "- Compare .nbytes\n",
            "### Hint Code\n",
            "- img = np.random.rand(224,224,3)\n",
            "- vid = np.random.rand(30,224,224,3)\n",
            "- print(\"Image bytes:\", img.nbytes)\n",
            "- print(\"Video bytes:\", vid.nbytes)\n",
            "### What You Learn\n",
            "- Why video models are expensive\n",
            "- Resource planning\n",
            "### TASK 7 — MINI BUSINESS DECISION\n",
            "- No specific tasks listed under this heading.\n",
            "### Real-World Problem: An AI system flags fraud transactions.\n",
            "- No specific tasks listed under this heading.\n",
            "### Your Objective: Decide a threshold that balances risk and cost.\n",
            "- No specific tasks listed under this heading.\n",
            "### Tasks\n",
            "- Generate random fraud probabilities\n",
            "- Try thresholds 0.5, 0.7, 0.9\n",
            "- Compare flagged cases\n",
            "### Hint Code\n",
            "- scores = np.random.rand(50)\n",
            "- for t in [0.5, 0.7, 0.9]:\n",
            "- print(f\"Threshold {t}: {len(scores[scores>t])} alerts\")\n",
            "### What You Learn\n",
            "- Threshold tuning\n",
            "- ML + business trade-offs\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "Now that the headings and tasks have been identified, please let me know which specific task you would like to proceed with, or if you have any other instructions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1e5b1e5"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Conclude the task by summarizing the identified tasks and preparing for the next steps based on user feedback.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae50df2a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The `python-docx` library was successfully installed after an initial `SyntaxError` due to a missing `!` prefix for the `pip install` command.\n",
        "*   The `/content/Tasks (1).docx` file was successfully loaded and its content extracted.\n",
        "*   The document parsing mechanism successfully identified 7 main tasks, along with their associated real-world problems, objectives, specific tasks, hint code, and learning outcomes, using predefined keywords.\n",
        "*   The identified tasks and their sub-components were structured and presented in a clear markdown format for easy review.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The system is now ready to proceed with any of the identified tasks from the `/content/Tasks (1).docx` document based on user selection.\n",
        "*   This approach demonstrates an effective method for automating the extraction and structuring of task-related information from document files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1de0d810"
      },
      "source": [
        "# Task\n",
        "Simulate a batch of 16 RGB images (224x224 pixels each) using NumPy, then print and explain the shape of the resulting tensor, detailing what each dimension represents for image processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bc5e20c"
      },
      "source": [
        "## TASK 1: Simulate Image Data\n",
        "\n",
        "### Subtask:\n",
        "Simulate a batch of 16 RGB images (224x224 pixels each) using NumPy, then print and explain the shape of the resulting tensor, detailing what each dimension represents for image processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a336b52"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to import the `numpy` library and create the simulated batch of images as a NumPy array with the specified dimensions. Then, I will print its shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05e872f3",
        "outputId": "3cc7cb68-4083-4d4f-df22-492453c02362"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array named `images` that simulates a batch of 16 RGB images, each with dimensions 224x224 pixels.\n",
        "images = np.random.rand(16, 224, 224, 3)\n",
        "\n",
        "# Print the shape of the `images` tensor\n",
        "print(\"Shape of the images tensor:\", images.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the images tensor: (16, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cdb499b"
      },
      "source": [
        "```markdown\n",
        "The shape of the `images` tensor is `(16, 224, 224, 3)`.\n",
        "\n",
        "Here's what each dimension represents:\n",
        "\n",
        "*   **First dimension (16):** This is the **batch size**, indicating that there are 16 individual images in this collection.\n",
        "*   **Second dimension (224):** This represents the **height** of each image in pixels.\n",
        "*   **Third dimension (224):** This represents the **width** of each image in pixels.\n",
        "*   **Fourth dimension (3):** This represents the **color channels** of each image. For an RGB image, there are 3 channels (Red, Green, Blue).\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1038db36"
      },
      "source": [
        "The shape of the `images` tensor is `(16, 224, 224, 3)`.\n",
        "\n",
        "Here's what each dimension represents:\n",
        "\n",
        "*   **First dimension (16):** This is the **batch size**, indicating that there are 16 individual images in this collection.\n",
        "*   **Second dimension (224):** This represents the **height** of each image in pixels.\n",
        "*   **Third dimension (224):** This represents the **width** of each image in pixels.\n",
        "*   **Fourth dimension (3):** This represents the **color channels** of each image. For an RGB image, there are 3 channels (Red, Green, Blue).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81af7955"
      },
      "source": [
        "## TASK 2: Simulate Video Data\n",
        "\n",
        "### Subtask:\n",
        "Simulate a video tensor representing a 10-second video at 30 FPS (300 frames), with each frame being an RGB image of 224x224 pixels, including a batch size of 1. Print and explain the shape of the video tensor, focusing on the time dimension.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7492f32d"
      },
      "source": [
        "**Reasoning**:\n",
        "To simulate the video tensor and print its shape, I will use NumPy to create an array with the specified dimensions: batch size (1), frames (10 seconds * 30 FPS = 300), height (224), width (224), and color channels (3 for RGB).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d37982f",
        "outputId": "e1d0b20e-807e-4da6-cde0-2298ad8cac77"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Simulate a video tensor representing a 10-second video at 30 FPS (300 frames),\n",
        "# with each frame being an RGB image of 224x224 pixels, and a batch size of 1.\n",
        "video_data = np.random.rand(1, 300, 224, 224, 3)\n",
        "\n",
        "# Print the shape of the video_data tensor\n",
        "print(\"Shape of the video tensor:\", video_data.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the video tensor: (1, 300, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af7dcf1f"
      },
      "source": [
        "The shape of the `video_data` tensor is `(1, 300, 224, 224, 3)`.\n",
        "\n",
        "Here's what each dimension represents:\n",
        "\n",
        "*   **First dimension (1):** This is the **batch size**, indicating that there is 1 video in this batch.\n",
        "*   **Second dimension (300):** This is the **time dimension** or **number of frames**, representing 300 frames (10 seconds * 30 FPS) for the video.\n",
        "*   **Third dimension (224):** This represents the **height** of each video frame in pixels.\n",
        "*   **Fourth dimension (224):** This represents the **width** of each video frame in pixels.\n",
        "*   **Fifth dimension (3):** This represents the **color channels** of each video frame. For an RGB image/frame, there are 3 channels (Red, Green, Blue)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "234b158a"
      },
      "source": [
        "## TASK 3: Simulate Churn Probability and Thresholding\n",
        "\n",
        "### Subtask:\n",
        "Generate 20 random customer churn probability predictions. Apply a decision threshold (e.g., 0.7) to identify and count customers classified as high-risk for churn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c9d8bb5"
      },
      "source": [
        "**Reasoning**:\n",
        "To simulate customer churn predictions and identify high-risk customers, I will use NumPy to generate random probabilities, define a threshold, and then filter the predictions to count those exceeding the threshold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f674c381",
        "outputId": "9cc2affc-8b3b-41de-e06a-d8c9cf7c18d1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate 20 random customer churn probability predictions\n",
        "churn_predictions = np.random.rand(20)\n",
        "\n",
        "# Define a decision threshold\n",
        "threshold = 0.7\n",
        "\n",
        "# Identify customers with churn probability greater than the threshold\n",
        "high_risk_customers = churn_predictions[churn_predictions > threshold]\n",
        "\n",
        "# Print the total number of customers classified as high-risk for churn\n",
        "print(f\"Original churn predictions:\\n{churn_predictions}\\n\")\n",
        "print(f\"High-risk churn predictions (above {threshold}):\\n{high_risk_customers}\\n\")\n",
        "print(f\"Number of high-risk customers: {len(high_risk_customers)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original churn predictions:\n",
            "[0.59234904 0.01398458 0.70393108 0.58159878 0.18871885 0.64742848\n",
            " 0.03265852 0.84057551 0.20301032 0.46104498 0.27941152 0.61422759\n",
            " 0.02867997 0.05024636 0.80603873 0.49006242 0.06597528 0.73397109\n",
            " 0.83517175 0.82330639]\n",
            "\n",
            "High-risk churn predictions (above 0.7):\n",
            "[0.70393108 0.84057551 0.80603873 0.73397109 0.83517175 0.82330639]\n",
            "\n",
            "Number of high-risk customers: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb4f2f23"
      },
      "source": [
        "## TASK 4: Calculate Feature Correlation\n",
        "\n",
        "### Subtask:\n",
        "Create two numerical lists representing advertising budget and sales data. Calculate the Pearson correlation coefficient between these two features using NumPy and interpret the result in terms of feature relevance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a453a34"
      },
      "source": [
        "**Reasoning**:\n",
        "To address the subtask, I will first create the specified numerical lists for advertising budget and sales, convert them into NumPy arrays, and then compute their Pearson correlation coefficient using `np.corrcoef()` as instructed. Finally, I will print the resulting correlation matrix.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ad5578",
        "outputId": "90e0821a-80e6-4c85-b2f5-5469224c28a8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create two numerical lists representing advertising budget and sales data\n",
        "ads = [100, 200, 300, 400, 500]\n",
        "sales = [10, 20, 30, 40, 50]\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "ads_array = np.array(ads)\n",
        "sales_array = np.array(sales)\n",
        "\n",
        "# Calculate the Pearson correlation coefficient\n",
        "correlation_matrix = np.corrcoef(ads_array, sales_array)\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcc69847"
      },
      "source": [
        "The correlation matrix `[[1. 1.] [1. 1.]]` shows the Pearson correlation coefficients between the advertising budget and sales data.\n",
        "\n",
        "Specifically, the off-diagonal elements (which are `1.`) represent the correlation between `ads` and `sales`.\n",
        "A correlation coefficient of `1.0` indicates a **perfect positive linear relationship** between the two variables.\n",
        "\n",
        "**Interpretation in terms of feature relevance:**\n",
        "\n",
        "This result suggests that there is a very strong and direct relationship between the advertising budget and sales. As the advertising budget increases, sales also increase proportionally. In a real-world scenario, this would mean that the advertising budget is a highly relevant feature for predicting or explaining sales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa820e51"
      },
      "source": [
        "## TASK 5: Simulate Model Learning\n",
        "\n",
        "### Subtask:\n",
        "Simulate 10 steps of a simple gradient descent algorithm to minimize a quadratic loss function, starting with an initial weight and learning rate. Print the weight and loss value at each step to observe the learning process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c4bf36"
      },
      "source": [
        "**Reasoning**:\n",
        "To simulate the gradient descent algorithm, I will create a code block that initializes the weight and learning rate, then iterates 10 times to update the weight and calculate the loss at each step, printing the results as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caee3874",
        "outputId": "36c0eb98-8cf7-429b-9b3b-8dea1bebe5b1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize a weight and learning rate\n",
        "w = 20\n",
        "lr = 0.1\n",
        "\n",
        "print(\"Simulating 10 steps of gradient descent:\")\n",
        "print(f\"Initial Weight: {w:.2f}\")\n",
        "\n",
        "# Loop 10 times to simulate 10 steps of gradient descent\n",
        "for i in range(1, 11):\n",
        "    # Calculate the current loss (quadratic function w^2)\n",
        "    loss = w**2\n",
        "\n",
        "    # Calculate the gradient of the loss with respect to the weight (d(w^2)/dw = 2w)\n",
        "    gradient = 2 * w\n",
        "\n",
        "    # Update the weight using the gradient descent formula\n",
        "    w = w - lr * gradient\n",
        "\n",
        "    # Print the step, updated weight, and loss\n",
        "    print(f\"Step {i}: Weight = {w:.2f}, Loss = {loss:.2f}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulating 10 steps of gradient descent:\n",
            "Initial Weight: 20.00\n",
            "Step 1: Weight = 16.00, Loss = 400.00\n",
            "Step 2: Weight = 12.80, Loss = 256.00\n",
            "Step 3: Weight = 10.24, Loss = 163.84\n",
            "Step 4: Weight = 8.19, Loss = 104.86\n",
            "Step 5: Weight = 6.55, Loss = 67.11\n",
            "Step 6: Weight = 5.24, Loss = 42.95\n",
            "Step 7: Weight = 4.19, Loss = 27.49\n",
            "Step 8: Weight = 3.36, Loss = 17.59\n",
            "Step 9: Weight = 2.68, Loss = 11.26\n",
            "Step 10: Weight = 2.15, Loss = 7.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80645827"
      },
      "source": [
        "## TASK 6: Compare Image vs. Video Memory Cost\n",
        "\n",
        "### Subtask:\n",
        "Create a single RGB image tensor (224x224 pixels) and a video tensor (30 frames, each 224x224 RGB). Calculate and compare the memory usage in bytes for both tensors using NumPy's `.nbytes` attribute.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6403cb6"
      },
      "source": [
        "**Reasoning**:\n",
        "To complete the subtask, I will create both an image and a video tensor using NumPy, calculate their memory usage in bytes, and then print these values along with a comparison statement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f7c6fe9",
        "outputId": "83437344-fb42-4ff5-eb8e-4cc1f481d785"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a single RGB image tensor (224x224 pixels)\n",
        "image_tensor = np.random.rand(224, 224, 3)\n",
        "\n",
        "# Create a video tensor (30 frames, each 224x224 RGB)\n",
        "video_tensor = np.random.rand(30, 224, 224, 3)\n",
        "\n",
        "# Calculate memory usage in bytes for both tensors\n",
        "image_memory_bytes = image_tensor.nbytes\n",
        "video_memory_bytes = video_tensor.nbytes\n",
        "\n",
        "# Print memory usages and comparison\n",
        "print(f\"Memory usage for image tensor: {image_memory_bytes} bytes\")\n",
        "print(f\"Memory usage for video tensor: {video_memory_bytes} bytes\")\n",
        "\n",
        "print(\"\\nComparison:\")\n",
        "if video_memory_bytes > image_memory_bytes:\n",
        "    ratio = video_memory_bytes / image_memory_bytes\n",
        "    print(f\"The video tensor uses {ratio:.2f} times more memory than the image tensor.\")\n",
        "elif image_memory_bytes > video_memory_bytes:\n",
        "    ratio = image_memory_bytes / video_memory_bytes\n",
        "    print(f\"The image tensor uses {ratio:.2f} times more memory than the video tensor.\")\n",
        "else:\n",
        "    print(\"Both tensors use the same amount of memory.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage for image tensor: 1204224 bytes\n",
            "Memory usage for video tensor: 36126720 bytes\n",
            "\n",
            "Comparison:\n",
            "The video tensor uses 30.00 times more memory than the image tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8339920e"
      },
      "source": [
        "The comparison shows that the **video tensor uses 30.00 times more memory than the image tensor**.\n",
        "\n",
        "This significant difference is directly attributable to the **time dimension** (or number of frames) in the video tensor. While a single image is a 3D array (height, width, channels), a video is essentially a sequence of images over time, making it a 4D array (frames, height, width, channels) or 5D if a batch dimension is included. In this specific simulation:\n",
        "\n",
        "*   **Image Tensor:** `(224, 224, 3)` represents one frame. Its memory usage is `224 * 224 * 3` units (assuming each value takes 1 unit of memory).\n",
        "*   **Video Tensor:** `(30, 224, 224, 3)` represents 30 frames. Its memory usage is `30 * 224 * 224 * 3` units.\n",
        "\n",
        "Therefore, the video tensor's memory requirement is proportional to the number of frames it contains relative to a single image, which in this case is 30 times greater. This illustrates why processing video data is generally more computationally and memory intensive than processing individual images, especially in deep learning applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32434fe1"
      },
      "source": [
        "## TASK 7: Evaluate Business Decision Thresholds\n",
        "\n",
        "### Subtask:\n",
        "Generate 50 random fraud probability scores. Test different decision thresholds (0.5, 0.7, 0.9) to count how many transactions would be flagged as fraudulent at each threshold, demonstrating the trade-offs in business decisions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c276010e"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate random fraud probability scores and apply different thresholds as requested in the subtask, I will use a code block to import NumPy, generate the scores, iterate through the thresholds, count the flagged cases, and print the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8d07c9f",
        "outputId": "c532510e-dfc1-4e74-ac52-0b7a96af05a9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate 50 random fraud probability scores\n",
        "fraud_scores = np.random.rand(50)\n",
        "\n",
        "# Define a list of thresholds to evaluate\n",
        "thresholds = [0.5, 0.7, 0.9]\n",
        "\n",
        "print(\"Evaluating fraud detection with different thresholds:\")\n",
        "for threshold in thresholds:\n",
        "    # Identify fraud scores greater than the current threshold\n",
        "    flagged_cases = fraud_scores[fraud_scores > threshold]\n",
        "\n",
        "    # Count the number of flagged cases\n",
        "    num_flagged = len(flagged_cases)\n",
        "\n",
        "    # Print the threshold and the number of flagged cases\n",
        "    print(f\"  Threshold {threshold}: {num_flagged} transactions flagged as fraudulent.\")\n",
        "\n",
        "print(\"\\nAll fraud scores:\")\n",
        "print(fraud_scores)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating fraud detection with different thresholds:\n",
            "  Threshold 0.5: 22 transactions flagged as fraudulent.\n",
            "  Threshold 0.7: 11 transactions flagged as fraudulent.\n",
            "  Threshold 0.9: 3 transactions flagged as fraudulent.\n",
            "\n",
            "All fraud scores:\n",
            "[4.94447646e-02 5.23574086e-01 5.18865670e-01 5.69157912e-01\n",
            " 1.96959615e-01 6.67124575e-01 6.80171926e-01 7.33106918e-01\n",
            " 2.60168599e-01 8.73460225e-01 4.80288147e-01 4.51138378e-01\n",
            " 8.94522933e-01 4.20804375e-01 8.66458562e-01 3.48530540e-01\n",
            " 1.60003385e-01 8.11381852e-03 9.14594570e-01 9.23971487e-01\n",
            " 3.17829665e-01 4.37382520e-01 7.02560972e-01 6.76496101e-02\n",
            " 5.74877681e-01 3.57706247e-01 4.34605747e-01 7.53795811e-01\n",
            " 7.53475459e-02 1.25048148e-01 8.88996574e-01 3.27714008e-01\n",
            " 2.00810555e-01 4.80002187e-01 4.11974928e-01 6.82882008e-01\n",
            " 1.73433138e-02 2.35448429e-01 4.65709852e-01 5.91785521e-01\n",
            " 8.75039439e-01 8.87276225e-02 8.14489162e-04 5.75818344e-01\n",
            " 9.32681110e-01 4.24841725e-02 3.14483713e-01 6.86584925e-01\n",
            " 2.22139700e-01 6.26946931e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a6f39a4"
      },
      "source": [
        "The output demonstrates the impact of choosing different thresholds for identifying fraudulent transactions:\n",
        "\n",
        "*   **Threshold 0.5**: With a threshold of 0.5, **22 transactions** were flagged as fraudulent. This is the most lenient threshold, meaning it catches more potential fraud. However, it also likely includes more false positives (legitimate transactions incorrectly flagged as fraud), leading to higher operational costs (e.g., investigating more cases) and potentially inconveniencing more customers.\n",
        "\n",
        "*   **Threshold 0.7**: Raising the threshold to 0.7 resulted in **11 transactions** being flagged. This is a more conservative approach. It reduces the number of flagged cases, which can decrease operational costs and false positives. However, it also means that some genuinely fraudulent transactions with scores between 0.5 and 0.7 might be missed (false negatives).\n",
        "\n",
        "*   **Threshold 0.9**: The most stringent threshold of 0.9 flagged only **3 transactions**. This approach minimizes false positives and associated costs, but it comes at the risk of missing a significant number of fraudulent transactions (high false negatives). Only the most obvious or high-confidence fraud cases are identified.\n",
        "\n",
        "**Trade-offs in Business Decisions:**\n",
        "\n",
        "This simulation highlights the critical trade-off in business decisions based on predictive models:\n",
        "\n",
        "*   **Lower Thresholds (e.g., 0.5)**: Increase recall (catch more fraud) but decrease precision (more false positives, higher operational cost, customer inconvenience).\n",
        "*   **Higher Thresholds (e.g., 0.9)**: Increase precision (fewer false positives, lower operational cost) but decrease recall (miss more fraud, higher financial loss due to undetected fraud).\n",
        "\n",
        "The optimal threshold depends on the specific business context, the cost of false positives versus false negatives, and the acceptable level of risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ca0fe74"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the completion of all 7 tasks and provide an overview of the outcomes and insights gained from each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "476ccdcf"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Task 1: Image Data Simulation**\n",
        "    A batch of 16 RGB images (224x224 pixels each) was successfully simulated using NumPy, resulting in a tensor of shape `(16, 224, 224, 3)`. Each dimension clearly represents the batch size, height, width, and RGB color channels, respectively.\n",
        "*   **Task 2: Video Data Simulation**\n",
        "    A video tensor, representing a 10-second video at 30 FPS (300 frames) with each frame as an RGB image of 224x224 pixels and a batch size of 1, was simulated. The resulting tensor had a shape of `(1, 300, 224, 224, 3)`, explicitly demonstrating the addition of a time/frame dimension.\n",
        "*   **Task 3: Churn Probability Thresholding**\n",
        "    Out of 20 random customer churn probability predictions, 6 customers were identified as high-risk for churn when a decision threshold of 0.7 was applied.\n",
        "*   **Task 4: Feature Correlation**\n",
        "    For the provided advertising budget and sales data, the Pearson correlation coefficient was calculated as `1.0`, indicating a perfect positive linear relationship between the two variables.\n",
        "*   **Task 5: Model Learning Simulation**\n",
        "    A 10-step gradient descent simulation for a quadratic loss function, starting with an initial weight of 20 and a learning rate of 0.1, showed the weight decreasing from 20.00 to 2.15 and the loss reducing consistently from 400.00 to 7.21.\n",
        "*   **Task 6: Memory Cost Comparison (Image vs. Video)**\n",
        "    A single RGB image tensor (224x224 pixels) consumed 1,204,224 bytes of memory, while a video tensor (30 frames, each 224x224 RGB) consumed 36,126,720 bytes. The video tensor used 30.00 times more memory than the image tensor, directly proportional to its number of frames.\n",
        "*   **Task 7: Business Decision Thresholds**\n",
        "    Evaluating 50 random fraud probability scores against different thresholds showed: 22 transactions flagged at threshold 0.5, 11 at 0.7, and 3 at 0.9. This clearly illustrated the trade-offs between catching more cases (lower threshold) and reducing false positives (higher threshold).\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Understanding data dimensionality is crucial for efficient data representation and memory management, especially when transitioning from static images to dynamic video sequences.\n",
        "*   Decision thresholds and model learning parameters like learning rates directly impact business outcomes and model performance; careful tuning is essential to balance precision, recall, and operational costs.\n"
      ]
    }
  ]
}