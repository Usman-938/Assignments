{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrAfj5P8JQP+Gv3r/v6zOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Usman-938/Assignments/blob/main/Real_Time_Object_Detection_%26_Tracking_Week4_(D3)_Home_Work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2c4b558",
        "outputId": "5463bbe9-cc3a-45b4-cc75-a550595d31c6"
      },
      "source": [
        "!python /content/real_time_detection_tracking.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries installed!\n",
            "Imports successful!\n",
            "Model loaded: YOLOv8n\n",
            "  Total classes : 80\n",
            "  Sample classes: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light']\n",
            "<IPython.core.display.Javascript object>\n",
            "Camera starting. Allow camera access. Detection runs for ~40 frames.\n",
            "Figure(1800x600)\n",
            "\n",
            "CONFIDENCE THRESHOLD COMPARISON TABLE\n",
            "===========================================================================\n",
            " Confidence Threshold  Detections Avg Confidence Inference Time (ms)       Classes Detected\n",
            "                 0.25           6           0.66               971.3 bus, stop sign, person\n",
            "                 0.50           4           0.85                10.4            bus, person\n",
            "                 0.75           4           0.85                 9.9            bus, person\n",
            "\n",
            "Saved: conf_threshold_comparison.png\n",
            "Creating synthetic test video...\n",
            "Synthetic video ready.\n",
            "Video: 200 frames @ 20.0 FPS\n",
            "Tracking complete: 150 frames processed\n",
            "  Unique Track IDs: []\n",
            "  Avg Tracking FPS: 125.74\n",
            "Figure(1800x1200)\n",
            "Saved: tracking_snapshots.png\n",
            "Figure(1400x1000)\n",
            "Saved: tracking_analysis.png\n",
            "Running performance analysis...\n",
            "  Single Object (clear): 95.5 FPS | 10.5 ms | 2.0 dets\n",
            "  Multiple Objects: 114.8 FPS | 8.7 ms | 4.0 dets\n",
            "  Fast Movement (simulated): 117.2 FPS | 8.5 ms | 4.0 dets\n",
            "  Low Light Conditions: 114.9 FPS | 8.7 ms | 4.0 dets\n",
            "  High Confidence (0.75): 114.4 FPS | 8.7 ms | 4.0 dets\n",
            "  Low Confidence (0.25): 106.2 FPS | 9.4 ms | 6.0 dets\n",
            "\n",
            "PERFORMANCE ANALYSIS TABLE\n",
            "===============================================================================================\n",
            "                 Scenario Avg FPS Inf Time (ms) Avg Detections          Tracking Stability\n",
            "    Single Object (clear)    95.5          10.5            2.0 High - consistent single ID\n",
            "         Multiple Objects   114.8           8.7            4.0  Medium - IDs mostly stable\n",
            "Fast Movement (simulated)   117.2           8.5            4.0  Low - frequent ID switches\n",
            "     Low Light Conditions   114.9           8.7            4.0     Low - missed detections\n",
            "   High Confidence (0.75)   114.4           8.7            4.0    High - fewer but precise\n",
            "    Low Confidence (0.25)   106.2           9.4            6.0   Medium - noisy detections\n",
            "===============================================================================================\n",
            "Figure(1600x400)\n",
            "Saved: performance_table.png\n",
            "Figure(1400x500)\n",
            "Saved: performance_chart.png\n",
            "===========================================================================\n",
            "CONCEPTUAL QUESTIONS AND ANSWERS\n",
            "===========================================================================\n",
            "\n",
            "Q: 1. Why is detection computationally heavier than tracking?\n",
            "A: \n",
            "Detection requires running the full neural network on every frame - extracting features across\n",
            "the entire image, proposing regions, classifying each, and regressing bounding boxes.\n",
            "This involves millions of floating-point operations per frame.\n",
            "\n",
            "Tracking (once objects are detected) only needs to:\n",
            "  - Predict next position using a Kalman Filter (simple linear algebra)\n",
            "  - Match predictions to new detections via IoU or appearance similarity (lightweight)\n",
            "  - Update track states\n",
            "\n",
            "Tracking works on compact bounding-box representations, not raw pixels,\n",
            "making it orders of magnitude faster than full detection.\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Q: 2. What is the role of a Kalman Filter in tracking?\n",
            "A: \n",
            "A Kalman Filter is a recursive algorithm that:\n",
            "  - PREDICTS where an object will be next, based on current position and estimated velocity\n",
            "  - UPDATES that prediction when a new detection arrives\n",
            "  - HANDLES NOISE by optimally weighting predictions vs measurements\n",
            "\n",
            "In tracking:\n",
            "  - During occlusion it keeps estimating position so the track survives\n",
            "  - On reappearance it matches the existing track, preventing a new ID\n",
            "  - Smooths jittery bounding-box estimates\n",
            "  - Assumes a constant-velocity motion model\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Q: 3. Why does ID switching occur?\n",
            "A: \n",
            "ID switching (object gets a new tracking ID) happens due to:\n",
            "  1. OCCLUSION - object hidden then reappears; tracker fails to re-associate it\n",
            "  2. MISSED DETECTIONS - YOLO misses the object for several frames; track is deleted\n",
            "  3. CROSSING PATHS - two similar objects cross; IoU matching swaps IDs\n",
            "  4. FAST MOVEMENT - object moves beyond the expected search region; match fails\n",
            "\n",
            "DeepSORT reduces switching by using Re-ID appearance embeddings in addition to IoU.\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Q: 4. Why is Non-Maximum Suppression (NMS) required?\n",
            "A: \n",
            "YOLO produces many overlapping bounding boxes for the same object because multiple\n",
            "nearby grid cells independently predict the same instance.\n",
            "\n",
            "Without NMS, one person might get 5-10 overlapping boxes.\n",
            "\n",
            "NMS algorithm:\n",
            "  1. Sort boxes by confidence (descending)\n",
            "  2. Keep the top-scoring box\n",
            "  3. Remove all boxes with IoU > threshold (e.g. 0.45) with the kept box\n",
            "  4. Repeat for remaining boxes\n",
            "\n",
            "Result: one clean, high-confidence bounding box per distinct object.\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Q: 5. Why is YOLO suitable for real-time applications?\n",
            "A: \n",
            "YOLO is built for speed because:\n",
            "  1. SINGLE PASS - the full image is processed in one forward pass (no separate proposal stage)\n",
            "  2. UNIFIED PREDICTION - detection and classification happen simultaneously\n",
            "  3. GRID ARCHITECTURE - each cell predicts boxes directly, avoiding redundant computation\n",
            "  4. SMALL VARIANTS - YOLOv8n/s sacrifice minor accuracy for extreme speed\n",
            "  5. GPU OPTIMISED - highly parallelisable convolutional operations\n",
            "\n",
            "Real-time threshold is ~24 FPS; YOLOv8n achieves 60-100+ FPS on a modern GPU.\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "ASSIGNMENT SUBMISSION SUMMARY\n",
            "============================================================\n",
            "Part A - Detection\n",
            "  Model            : YOLOv8n (pretrained, 80 COCO classes)\n",
            "  Webcam capture   : JavaScript bridge in Colab\n",
            "  Conf thresholds  : 0.25 / 0.50 / 0.75\n",
            "  Outputs          : fps_plot.png, conf_threshold_comparison.png\n",
            "\n",
            "Part B - Tracking (ByteTrack)\n",
            "  Unique IDs seen  : []\n",
            "  Avg tracking FPS : 125.74\n",
            "  Outputs          : tracking_snapshots.png, tracking_analysis.png\n",
            "\n",
            "Part C - Performance Analysis\n",
            "  Scenarios tested : 6\n",
            "  Outputs          : performance_table.png, performance_chart.png\n",
            "\n",
            "Part D - Conceptual Questions: All 5 answered above\n",
            "\n",
            "============================================================\n",
            "Assignment Complete!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}